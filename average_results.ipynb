{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "experiment_name = \"/cluster/work/lawecon/Work/mbraasch/output/TEC\"\n",
    "\n",
    "# Find all paths that end with directory \"m2345678\", \"m3456789\", \"m456789\", \"m12345678\"\n",
    "runs = list(range(1, 6))\n",
    "experts = [\"m2345678\", \"m345678\", \"m45678\"]\n",
    "# experts = [\"m12345678\"]\n",
    "datasets = [\"socratic\", \"dl\", \"gt\"]\n",
    "models = [\n",
    "    \"google--gemma-1.1-2b-it\",\n",
    "    \"mistralai--Mistral-7B-Instruct-v0.3\",\n",
    "    \"deepseek-ai--deepseek-llm-7b-chat\"\n",
    "]\n",
    "postfixes = [\n",
    "    \"_TEC_from_gt_1_BL\",\n",
    "    \"_TEC_from_gt_2_BL\",\n",
    "    \"_TEC_from_gt_3_BL\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m2345678 google--gemma-1.1-2b-it socratic _TEC_from_gt\n",
      "0.36254738438210765\n",
      "m2345678 google--gemma-1.1-2b-it dl _TEC_from_gt\n",
      "0.37225170583775585\n",
      "m2345678 google--gemma-1.1-2b-it gt _TEC_from_gt\n",
      "0.35451099317664897\n",
      "m2345678 mistralai--Mistral-7B-Instruct-v0.3 socratic _TEC_from_gt\n",
      "0.44776345716451854\n",
      "m2345678 mistralai--Mistral-7B-Instruct-v0.3 dl _TEC_from_gt\n",
      "0.48006065200909787\n",
      "m2345678 mistralai--Mistral-7B-Instruct-v0.3 gt _TEC_from_gt\n",
      "0.45868081880212286\n",
      "m2345678 deepseek-ai--deepseek-llm-7b-chat socratic _TEC_from_gt\n",
      "0.5724033358605004\n",
      "m2345678 deepseek-ai--deepseek-llm-7b-chat dl _TEC_from_gt\n",
      "0.6156178923426839\n",
      "m2345678 deepseek-ai--deepseek-llm-7b-chat gt _TEC_from_gt\n",
      "0.5760424564063685\n",
      "m345678 google--gemma-1.1-2b-it socratic _TEC_from_gt\n",
      "0.41107754279959713\n",
      "m345678 google--gemma-1.1-2b-it dl _TEC_from_gt\n",
      "0.40805639476334343\n",
      "m345678 google--gemma-1.1-2b-it gt _TEC_from_gt\n",
      "0.3925478348439074\n",
      "m345678 mistralai--Mistral-7B-Instruct-v0.3 socratic _TEC_from_gt\n",
      "0.4974823766364552\n",
      "m345678 mistralai--Mistral-7B-Instruct-v0.3 dl _TEC_from_gt\n",
      "0.4956696878147029\n",
      "m345678 mistralai--Mistral-7B-Instruct-v0.3 gt _TEC_from_gt\n",
      "0.47029204431017124\n",
      "m345678 deepseek-ai--deepseek-llm-7b-chat socratic _TEC_from_gt\n",
      "0.6195367573011077\n",
      "m345678 deepseek-ai--deepseek-llm-7b-chat dl _TEC_from_gt\n",
      "0.6229607250755287\n",
      "m345678 deepseek-ai--deepseek-llm-7b-chat gt _TEC_from_gt\n",
      "0.6042296072507554\n",
      "m45678 google--gemma-1.1-2b-it socratic _TEC_from_gt\n",
      "0.4478330658105939\n",
      "m45678 google--gemma-1.1-2b-it dl _TEC_from_gt\n",
      "0.42343499197431783\n",
      "m45678 google--gemma-1.1-2b-it gt _TEC_from_gt\n",
      "0.4192616372391654\n",
      "m45678 mistralai--Mistral-7B-Instruct-v0.3 socratic _TEC_from_gt\n",
      "0.5232744783306581\n",
      "m45678 mistralai--Mistral-7B-Instruct-v0.3 dl _TEC_from_gt\n",
      "0.525521669341894\n",
      "m45678 mistralai--Mistral-7B-Instruct-v0.3 gt _TEC_from_gt\n",
      "0.49181380417335474\n",
      "m45678 deepseek-ai--deepseek-llm-7b-chat socratic _TEC_from_gt\n",
      "0.614446227929374\n",
      "m45678 deepseek-ai--deepseek-llm-7b-chat dl _TEC_from_gt\n",
      "0.626645264847512\n",
      "m45678 deepseek-ai--deepseek-llm-7b-chat gt _TEC_from_gt\n",
      "0.6170144462279293\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        for postfix in postfixes:\n",
    "            \n",
    "            accs = []\n",
    "            for run in runs:\n",
    "                file_path = os.path.join(experiment_name, model, dataset, \"m12345678\", str(run), f\"accuracy{postfix}.json\")\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    accs.append(json.load(f)[\"accuracy\"])\n",
    "            avg_acc = sum(accs) / len(accs)\n",
    "            \n",
    "            # Write to the output file\n",
    "            output_file = os.path.join(experiment_name, model, dataset, \"m12345678\", f\"accuracy{postfix}.json\")\n",
    "            with open(output_file, \"w\") as f:\n",
    "                json.dump({\"accuracy\": avg_acc}, f)\n",
    "\n",
    "            # Print accuracy to the console for easy copy-pasting\n",
    "            print(model, dataset, postfix)\n",
    "            print(avg_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
