######################### Training pipeline #################

sbatch --gpus=rtx_4090:1 --mem-per-cpu=8G --wrap="python3 sft/training_pipeline.py"
sbatch --gpus=rtx_4090:1 --mem-per-cpu=8G --wrap="python3 sft/inference_chain.py"
sbatch --gpus=rtx_4090:1 --mem-per-cpu=8G --wrap="python3 sft/inspect_model.py"


sbatch --wrap="python3 sft/evaluate.py --run_name gemma-2b-it;

######################### Training #########################

    --time=0-2 \
Baseline
sbatch \
    --gpus=rtx_3090:1 \
    --mem-per-cpu=8G \
    --wrap="python3 sft/run_sft.py \
        --run_name /cluster/work/lawecon/Work/mbraasch/output/gemma-2b-it \
        --instruction \"Solve the given math problem step by step and put your final answer after 'Final answer: '.\" \
        --data_path /cluster/work/lawecon/Work/mbraasch/output/gemma-2b-it/data/train.json;"

M1
sbatch \
    --gpus=rtx_3090:1 \
    --mem-per-cpu=8G \
    --wrap="python3 sft/run_sft.py \
        --model_type m1 \
        --run_name deepseek-7b-base-m1 \
        --data_path decomposed/train/normal/1.json";

M2
sbatch \
    --gpus=rtx_4090:1 \
    --mem-per-cpu=8G \
    --wrap="python3 sft/run_sft.py \
        --model_type mi \
        --run_name deepseek-7b-base-m2 \
        --data_path decomposed/train/normal/2.json";

######################### Inference #########################

# Base inference
sbatch \
    --gpus=rtx_4090:1 \
    --mem-per-cpu=16G \
    --wrap="python3 sft/inference.py \
        --data_path baseline/test.json \
        --model_type bl \
        --run_name deepseek-7b-base-baseline";
sbatch \
    --gpus=rtx_3090:1 \
    --mem-per-cpu=16G \
    --wrap="python3 sft/inference.py \
        --data_path baseline/test.json \
        --model_type bl \
        --run_name deepseek-7b-base-baseline";

# M1 inference
sbatch \
    --gpus=rtx_3090:1 \
    --mem-per-cpu=16G \
    --wrap="python3 sft/inference.py \
        --data_path decomposed/test/normal/1.json \
        --model_type m1 \
        --run_name deepseek-7b-base-m1";
sbatch \
    --gpus=rtx_4090:1 \
    --mem-per-cpu=16G \
    --wrap="python3 sft/inference.py \
        --data_path decomposed/test/normal/1.json \
        --model_type m1 \
        --run_name deepseek-7b-base-m1";
59159401
59159403

# M2 inference
sbatch \
    --gpus=rtx_3090:1 \
    --mem-per-cpu=16G \
    --wrap="python3 sft/inference.py \
        --data_path decomposed/test/normal/2.json \
        --model_type mi \
        --run_name deepseek-7b-base-m2";
sbatch \
    --gpus=rtx_4090:1 \
    --mem-per-cpu=16G \
    --wrap="python3 sft/inference.py \
        --data_path decomposed/test/normal/2.json \
        --model_type mi \
        --run_name deepseek-7b-base-m2";
59159491
59159493

######################### Evaluate #########################

# Evaluate baseline performance overall
sbatch --wrap="python3 sft/evaluate.py --run_name deepseek-7b-base-baseline"

# Evaluate baseline final
sbatch --wrap="python3 sft/evaluate.py --run_name gemma-2b-it;

# Evaluate baseline step 1
sbatch --wrap="python3 sft/evaluate.py \
    --run_name deepseek-7b-base-baseline \
    --step 1 \
    --postprocessed_name postprocessed_step_1.json \
    --metrics_name model_metrics_step_1.json";

# Evaluate baseline step 2
sbatch --wrap="python3 sft/evaluate.py \
    --run_name deepseek-7b-base-baseline \
    --step 3 \
    --postprocessed_name postprocessed_step_3.json \
    --metrics_name model_metrics_step_3.json";

sbatch --wrap="python3 sft/evaluate.py --run_name deepseek-7b-base-m1 --step 1"
sbatch --wrap="python3 sft/evaluate.py --run_name deepseek-7b-base-m2 --step 2"
